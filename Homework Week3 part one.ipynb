{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f927e50a",
   "metadata": {},
   "source": [
    "# 1. Download the [dog heart datasets](https://github.com/YoushanZhang/Dog-Cardiomegaly) (10 points) resize image to (224, 224)\n",
    "\n",
    "### (1). Create a train data loader that returns image arrays and labels\n",
    "### (2). Create a test data loader that returns image arrays and file names (Note validation data is not used here, it is unlabeled test dataset, DO NOT USE VALIDATION dataset for this part)\n",
    "### (3). Print image arrays, labels and file names dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ffda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8fd11",
   "metadata": {},
   "source": [
    "First, create Dataset classes for labeled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8c10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogHeartLabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.data_root: str = data_root\n",
    "        self.classes: List[str] = os.listdir(data_root)\n",
    "        self.class_to_idx: Dict[str, int] = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.filenames: List[str] = []\n",
    "        self.filepaths: List[str] = []\n",
    "        self.labels: List[int] = []\n",
    "\n",
    "        for class_name in self.classes:\n",
    "            path: str = os.path.join(data_root, class_name)\n",
    "            for filename in os.listdir(path):\n",
    "                self.filenames.append(filename)\n",
    "                self.filepaths.append(os.path.join(path, filename))\n",
    "                self.labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, str]:\n",
    "        filename: str = self.filenames[idx]\n",
    "        filepath: str = self.filepaths[idx]\n",
    "        image: Image = Image.open(filepath)\n",
    "        label: torch.Tensor = torch.tensor(self.labels[idx])\n",
    "        tensor: torch.Tensor = self.transformation(image)\n",
    "        tensor = tensor.squeeze(0)\n",
    "        return tensor, label, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123ea7e",
   "metadata": {},
   "source": [
    "Create Dataset class for unlabeled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ce8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogHearUnlabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.data_root: str = data_root\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "        self.filenames: List[str] = os.listdir(self.data_root)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, str]:\n",
    "        filename: str = self.filenames[idx]\n",
    "        image: Image = Image.open(os.path.join(self.data_root, filename))\n",
    "        tensor: torch.Tensor = self.transformation(image)\n",
    "        tensor = tensor.squeeze(0)\n",
    "        return tensor, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483f283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Train')\n",
    "valid_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Valid')\n",
    "test_dataset = DogHearUnlabeledDataset(data_root='Test')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b137d",
   "metadata": {},
   "source": [
    "Dimensions of train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15374c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1400, 224, 224])\n",
      "torch.Size([1400])\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, train_filenames = next(iter(train_dataloader))\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(len(train_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065acf92",
   "metadata": {},
   "source": [
    "Dimensions of validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b124ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 224, 224])\n",
      "torch.Size([200])\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "valid_images, valid_labels, valid_filenames = next(iter(valid_dataloader))\n",
    "print(valid_images.shape)\n",
    "print(valid_labels.shape)\n",
    "print(len(valid_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39196d9c",
   "metadata": {},
   "source": [
    "Dimensions of test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579ac6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 224, 224])\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "test_images, test_filenames = next(iter(test_dataloader))\n",
    "print(test_images.shape)\n",
    "print(len(test_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5ec7c",
   "metadata": {},
   "source": [
    "# 2. Extract features of training and test images using HOG (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1400 * d, test features: 400 *d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "053db69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "\n",
    "from datasets import DogHeartLabeledDataset\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skimage.feature\n",
    "\n",
    "import torch\n",
    "import torch.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4fdf7",
   "metadata": {},
   "source": [
    "First, create an abstract `FeatureExtractor` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea4ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, image_array: np.ndarray) -> np.ndarray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113cc7d0",
   "metadata": {},
   "source": [
    "Create the `HOG` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f77b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOG(FeatureExtractor):\n",
    "\n",
    "    def __init__(self, channel_axis: int = None) -> None:\n",
    "        self.channel_axis: int = channel_axis\n",
    "\n",
    "    def __call__(self, image_array: np.ndarray) -> np.ndarray:\n",
    "        return skimage.feature.hog(image=image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1123cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Train')\n",
    "valid_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Valid')\n",
    "\n",
    "hog = HOG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5e559",
   "metadata": {},
   "source": [
    "HOG feature extractor on Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c994b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 54756)\n"
     ]
    }
   ],
   "source": [
    "train_hog_features: List[np.ndarray] = []\n",
    "for image, label, filename in train_dataset:\n",
    "    hog_feature = hog(image_array=image.numpy())\n",
    "    train_hog_features.append(hog_feature)\n",
    "\n",
    "train_hog_features = np.stack(arrays=train_hog_features, axis=0)\n",
    "print(train_hog_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e73c6",
   "metadata": {},
   "source": [
    "HOG feature extractor on Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a31ada1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 54756)\n"
     ]
    }
   ],
   "source": [
    "valid_hog_features: List[np.ndarray] = []\n",
    "for image, label, filename in valid_dataset:\n",
    "    hog_feature = hog(image_array=image.numpy())\n",
    "    valid_hog_features.append(hog_feature)\n",
    "\n",
    "valid_hog_features = np.stack(arrays=valid_hog_features, axis=0)\n",
    "print(valid_hog_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049f8e0",
   "metadata": {},
   "source": [
    "HOG feature extractor on Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4da21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 54756)\n"
     ]
    }
   ],
   "source": [
    "test_hog_features: List[np.ndarray] = []\n",
    "for image, filename in test_dataset:\n",
    "    hog_feature = hog(image_array=image.numpy())\n",
    "    test_hog_features.append(hog_feature)\n",
    "\n",
    "test_hog_features = np.stack(arrays=test_hog_features, axis=0)\n",
    "print(test_hog_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5339f5",
   "metadata": {},
   "source": [
    "# 3. Extract features of training and test images using SIFT (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1400 * d, test features: 400 *d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe346a",
   "metadata": {},
   "source": [
    "Create the `SIFT` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4944d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIFT(FeatureExtractor):\n",
    "\n",
    "    def __init__(self, n_features: int):\n",
    "        self.n_features: int = n_features\n",
    "        self.sift: cv2.SIFT = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    def __call__(self, image_array: np.ndarray) -> np.ndarray:\n",
    "        keypoints: List[cv2.KeyPoint]\n",
    "        descriptors: np.ndarray\n",
    "        keypoints, descriptors = self.sift.detectAndCompute(\n",
    "            image=(image_array * 255).astype(np.uint8), \n",
    "            mask=None,\n",
    "        )   # (keypoints, descriptors)\n",
    "\n",
    "        assert len(keypoints) == descriptors.shape[0]\n",
    "        indices: np.ndarray = np.argsort([kp.response for kp in keypoints])[::-1][:self.n_features]\n",
    "\n",
    "        keypoints: List[cv2.KeyPoint] = [keypoints[idx] for idx in indices]\n",
    "        features: np.ndarray = descriptors[indices]\n",
    "        if features.shape[0] < self.n_features:\n",
    "            padding = np.zeros(shape=(self.n_features - features.shape[0], features.shape[1]))\n",
    "            features = np.concatenate((features, padding), axis=0)\n",
    "        \n",
    "        features: np.ndarray = features.flatten()\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e40d5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = SIFT(n_features=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4f32e",
   "metadata": {},
   "source": [
    "SIFT feature extractor on Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "247ecd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 3840)\n"
     ]
    }
   ],
   "source": [
    "train_sift_features: List[np.ndarray] = []\n",
    "for image, label, filename in train_dataset:\n",
    "    sift_feature = sift(image_array=image.numpy())\n",
    "    train_sift_features.append(sift_feature)\n",
    "\n",
    "train_sift_features = np.stack(arrays=train_sift_features, axis=0)\n",
    "print(train_sift_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91100d5a",
   "metadata": {},
   "source": [
    "SIFT feature extractor on Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eb6ea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3840)\n"
     ]
    }
   ],
   "source": [
    "valid_sift_features: List[np.ndarray] = []\n",
    "for image, label, filename in valid_dataset:\n",
    "    sift_feature = sift(image_array=image.numpy())\n",
    "    valid_sift_features.append(sift_feature)\n",
    "\n",
    "valid_sift_features = np.stack(arrays=valid_sift_features, axis=0)\n",
    "print(valid_sift_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c863f41",
   "metadata": {},
   "source": [
    "SIFT feature extractor on Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56ce5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3840)\n"
     ]
    }
   ],
   "source": [
    "test_sift_features: List[np.ndarray] = []\n",
    "for image, filename in test_dataset:\n",
    "    sift_feature = sift(image_array=image.numpy())\n",
    "    test_sift_features.append(sift_feature)\n",
    "\n",
    "test_sift_features = np.stack(arrays=test_sift_features, axis=0)\n",
    "print(test_sift_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753188e2",
   "metadata": {},
   "source": [
    "# 4. Extract features of training and test images using SURF (20 points)\n",
    "Please print the size of extracted features, e.g., training features: 1400 * d, test features: 400 *d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761abf18",
   "metadata": {},
   "source": [
    "Create the `SURF` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5511a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SURF(FeatureExtractor):\n",
    "\n",
    "    def __init__(self, n_features: int):\n",
    "        self.n_features: int = n_features\n",
    "        self.surf: cv2.xfeatures2d_SURF = cv2.xfeatures2d.SURF_create(nOctaves=5)\n",
    "\n",
    "    def __call__(self, image_array: np.ndarray) -> np.ndarray:\n",
    "        keypoints: List[cv2.KeyPoint]\n",
    "        descriptors: np.ndarray\n",
    "        keypoints, descriptors = self.surf.detectAndCompute(\n",
    "            image=(image_array * 255).astype(np.uint8), \n",
    "            mask=None,\n",
    "        )   # (keypoints, descriptors)\n",
    "\n",
    "        assert len(keypoints) == descriptors.shape[0]\n",
    "        indices: np.ndarray = np.argsort([kp.response for kp in keypoints])[::-1][:self.n_features]\n",
    "\n",
    "        keypoints: List[cv2.KeyPoint] = [keypoints[idx] for idx in indices]\n",
    "        features: np.ndarray = descriptors[indices]\n",
    "        if features.shape[0] < self.n_features:\n",
    "            padding = np.zeros(shape=(self.n_features - features.shape[0], features.shape[1]))\n",
    "            features = np.concatenate((features, padding), axis=0)\n",
    "\n",
    "        features = features.flatten()\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce779c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = SURF(n_features=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee93fc7",
   "metadata": {},
   "source": [
    "SURF feature extractor on Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dc9426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 1920)\n"
     ]
    }
   ],
   "source": [
    "train_surf_features: List[np.ndarray] = []\n",
    "for image, label, filename in train_dataset:\n",
    "    surf_feature = surf(image_array=image.numpy())\n",
    "    train_surf_features.append(surf_feature)\n",
    "\n",
    "train_surf_features = np.stack(arrays=train_surf_features, axis=0)\n",
    "print(train_surf_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5967ae",
   "metadata": {},
   "source": [
    "SURF feature extractor on Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b86f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1920)\n"
     ]
    }
   ],
   "source": [
    "valid_surf_features: List[np.ndarray] = []\n",
    "for image, label, filename in valid_dataset:\n",
    "    surf_feature = surf(image_array=image.numpy())\n",
    "    valid_surf_features.append(surf_feature)\n",
    "\n",
    "valid_surf_features = np.stack(arrays=valid_surf_features, axis=0)\n",
    "print(valid_surf_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3c30f",
   "metadata": {},
   "source": [
    "SURF feature extractor on Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "432c23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1920)\n"
     ]
    }
   ],
   "source": [
    "test_surf_features: List[np.ndarray] = []\n",
    "for image, filename in test_dataset:\n",
    "    surf_feature = surf(image_array=image.numpy())\n",
    "    test_surf_features.append(surf_feature)\n",
    "\n",
    "test_surf_features = np.stack(arrays=test_surf_features, axis=0)\n",
    "print(test_surf_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3e068",
   "metadata": {},
   "source": [
    "# 5. Call SVM and kNN from scikit-learn and train the extracted HOG, SIFT and SURF features, respectively, save three CSV files of test dataset using three features (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ce997b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from feature_extractors import FeatureExtractor\n",
    "from datasets import DogHeartLabeledDataset, DogHearUnlabeledDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9aae88",
   "metadata": {},
   "source": [
    "Create the class `Predictor` that accepts one `Estimator` and one `FeatureExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db86d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: BaseEstimator,\n",
    "        feature_extractor: FeatureExtractor,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.feature_extractor: FeatureExtractor = feature_extractor\n",
    "\n",
    "    def fit(self, train_dataset: Dataset) -> None:\n",
    "        train_dataloader = DataLoader(dataset=train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "        \n",
    "        images: torch.Tensor; labels: torch.Tensor; filenames: List[str]\n",
    "        images, labels, filenames = next(iter(train_dataloader))\n",
    "        \n",
    "        images: np.ndarray = images.numpy()\n",
    "        labels: np.ndarray = labels.numpy()\n",
    "        \n",
    "        train_features: List[np.ndarray] = []\n",
    "        for image in images:\n",
    "            feature = self.feature_extractor(image_array=image)\n",
    "            train_features.append(feature)\n",
    "\n",
    "        train_features = np.stack(arrays=train_features, axis=0)\n",
    "        self.model.fit(X=train_features, y=labels)\n",
    "\n",
    "    def predict(self, test_dataset: Dataset) -> np.ndarray:\n",
    "        test_dataloader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "        \n",
    "        image: torch.Tensor; filenames: List[str]\n",
    "        images, filenames = next(iter(test_dataloader))\n",
    "\n",
    "        images: np.ndarray = images.numpy()\n",
    "\n",
    "        test_features: List[np.ndarray] = []\n",
    "        for image in images:\n",
    "            feature = self.feature_extractor(image_array=image).reshape(-1)\n",
    "            test_features.append(feature)\n",
    "\n",
    "        predicted_labels: np.ndarray = self.model.predict(X=np.array(test_features))\n",
    "        prediction_table = pd.DataFrame(\n",
    "            data={'image': filenames, 'label': predicted_labels}\n",
    "        )\n",
    "        prediction_table.to_csv(\n",
    "            f'{self.model.__class__.__name__}_{self.feature_extractor.__class__.__name__}.csv', \n",
    "            header=False, \n",
    "            index=False,\n",
    "        )\n",
    "        return prediction_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168f29c",
   "metadata": {},
   "source": [
    "Load train (labeled) and test (unlabeled) datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cd79225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Train')\n",
    "test_dataset = DogHearUnlabeledDataset('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d50bc",
   "metadata": {},
   "source": [
    "`SVM + HOG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3804c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1685.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1833.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1900.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1824.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1907.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1922.png      2\n",
       "1    1709.png      1\n",
       "2    1919.png      0\n",
       "3    1639.png      0\n",
       "4    1804.png      2\n",
       "..        ...    ...\n",
       "395  1685.png      2\n",
       "396  1833.png      2\n",
       "397  1900.png      0\n",
       "398  1824.png      2\n",
       "399  1907.png      2\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_hog = Predictor(model=SVC(), feature_extractor=HOG())\n",
    "svm_hog.fit(train_dataset=train_dataset)\n",
    "svm_hog.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b07a9",
   "metadata": {},
   "source": [
    "`KNN + HOG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f5aaeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1685.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1833.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1900.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1824.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1907.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1922.png      2\n",
       "1    1709.png      1\n",
       "2    1919.png      0\n",
       "3    1639.png      0\n",
       "4    1804.png      2\n",
       "..        ...    ...\n",
       "395  1685.png      2\n",
       "396  1833.png      2\n",
       "397  1900.png      0\n",
       "398  1824.png      2\n",
       "399  1907.png      0\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_hog = Predictor(model=KNeighborsClassifier(n_neighbors=1), feature_extractor=HOG())\n",
    "knn_hog.fit(train_dataset=train_dataset)\n",
    "knn_hog.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2cdfe",
   "metadata": {},
   "source": [
    "`SVM + SIFT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68704a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1639.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1685.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1833.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1900.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1824.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1907.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1922.png      0\n",
       "1    1709.png      1\n",
       "2    1919.png      0\n",
       "3    1639.png      2\n",
       "4    1804.png      0\n",
       "..        ...    ...\n",
       "395  1685.png      2\n",
       "396  1833.png      2\n",
       "397  1900.png      0\n",
       "398  1824.png      0\n",
       "399  1907.png      2\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_sift = Predictor(model=SVC(), feature_extractor=SIFT(n_features=30))\n",
    "svm_sift.fit(train_dataset=train_dataset)\n",
    "svm_sift.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd0261",
   "metadata": {},
   "source": [
    "`KNN + SIFT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d599ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1685.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1833.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1900.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1824.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1907.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1922.png      0\n",
       "1    1709.png      1\n",
       "2    1919.png      0\n",
       "3    1639.png      0\n",
       "4    1804.png      1\n",
       "..        ...    ...\n",
       "395  1685.png      2\n",
       "396  1833.png      2\n",
       "397  1900.png      0\n",
       "398  1824.png      0\n",
       "399  1907.png      2\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_sift = Predictor(model=KNeighborsClassifier(n_neighbors=1), feature_extractor=SIFT(n_features=30))\n",
    "knn_sift.fit(train_dataset=train_dataset)\n",
    "knn_sift.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863e50b",
   "metadata": {},
   "source": [
    "`SVM + SURF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ef82c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1685.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1833.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1900.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1824.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1907.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1922.png      0\n",
       "1    1709.png      0\n",
       "2    1919.png      0\n",
       "3    1639.png      0\n",
       "4    1804.png      2\n",
       "..        ...    ...\n",
       "395  1685.png      2\n",
       "396  1833.png      2\n",
       "397  1900.png      0\n",
       "398  1824.png      2\n",
       "399  1907.png      2\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_surf = Predictor(model=SVC(), feature_extractor=SURF(n_features=30))\n",
    "svm_surf.fit(train_dataset=train_dataset)\n",
    "svm_surf.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbcfe8",
   "metadata": {},
   "source": [
    "`KNN + SURF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e622658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1685.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1833.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1900.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1824.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1907.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1922.png      0\n",
       "1    1709.png      0\n",
       "2    1919.png      0\n",
       "3    1639.png      0\n",
       "4    1804.png      2\n",
       "..        ...    ...\n",
       "395  1685.png      0\n",
       "396  1833.png      2\n",
       "397  1900.png      2\n",
       "398  1824.png      0\n",
       "399  1907.png      2\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_surf = Predictor(model=KNeighborsClassifier(n_neighbors=1), feature_extractor=SURF(n_features=30))\n",
    "knn_surf.fit(train_dataset=train_dataset)\n",
    "knn_surf.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd101cf",
   "metadata": {},
   "source": [
    "# 6. Report the accuracy using Dog_X_ray_classfication_accuracy software, please attach the results image here (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea49db",
   "metadata": {},
   "source": [
    "### (1). SVM and 1NN using HOG features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c2814",
   "metadata": {},
   "source": [
    "`SVM + HOG`:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/DLAssignment3/master/SVC_HOG.png\" style=\"width:50%;\">\n",
    "\n",
    "\n",
    "`KNN + HOG`:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/DLAssignment3/master/KNN_HOG.png\" style=\"width:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163e551",
   "metadata": {},
   "source": [
    "### (2). SVM and 1NN using SIFT features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a960265",
   "metadata": {},
   "source": [
    "`SVM + SIFT`:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/DLAssignment3/master/SVC_SIFT.png\" style=\"width:50%;\">\n",
    "\n",
    "\n",
    "`KNN + SIFT`:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/DLAssignment3/master/KNN_SIFT.png\" style=\"width:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908c75a",
   "metadata": {},
   "source": [
    "### (3). SVM and 1NN using SURF features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283926a",
   "metadata": {},
   "source": [
    "`SVM + SURF`:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/DLAssignment3/master/SVC_SURF.png\" style=\"width:50%;\">\n",
    "\n",
    "\n",
    "`KNN + SIFT`:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/DLAssignment3/master/KNN_SURF.png\" style=\"width:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dae97a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
