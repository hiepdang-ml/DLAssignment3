{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009e8fc2",
   "metadata": {},
   "source": [
    "# 1. Build your own neural network with 3 hidden layers using pytorch (60 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64cb564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage.feature\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2fdb4d",
   "metadata": {},
   "source": [
    "Redefine dataset classes and feature extractors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae75236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogHeartLabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.data_root: str = data_root\n",
    "        self.classes: List[str] = os.listdir(data_root)\n",
    "        self.class_to_idx: Dict[str, int] = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.filenames: List[str] = []\n",
    "        self.filepaths: List[str] = []\n",
    "        self.labels: List[int] = []\n",
    "\n",
    "        for class_name in self.classes:\n",
    "            path: str = os.path.join(data_root, class_name)\n",
    "            for filename in os.listdir(path):\n",
    "                self.filenames.append(filename)\n",
    "                self.filepaths.append(os.path.join(path, filename))\n",
    "                self.labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, str]:\n",
    "        filename: str = self.filenames[idx]\n",
    "        filepath: str = self.filepaths[idx]\n",
    "        image: Image = Image.open(filepath)\n",
    "        label: torch.Tensor = torch.tensor(self.labels[idx])\n",
    "        tensor: torch.Tensor = self.transformation(image)\n",
    "        tensor = tensor.squeeze(0)\n",
    "        return tensor, label, filename\n",
    "    \n",
    "\n",
    "class DogHearUnlabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root: str) -> None:\n",
    "        self.data_root: str = data_root\n",
    "        self.transformation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "        self.filenames: List[str] = os.listdir(self.data_root)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, str]:\n",
    "        filename: str = self.filenames[idx]\n",
    "        image: Image = Image.open(os.path.join(self.data_root, filename))\n",
    "        tensor: torch.Tensor = self.transformation(image)\n",
    "        tensor = tensor.squeeze(0)\n",
    "        return tensor, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a14cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, image_array: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "    \n",
    "\n",
    "class HOG(FeatureExtractor):\n",
    "\n",
    "    def __init__(self, channel_axis: int = None) -> None:\n",
    "        self.channel_axis: int = channel_axis\n",
    "\n",
    "    def __call__(self, image_array: np.ndarray) -> np.ndarray:\n",
    "        return skimage.feature.hog(image=image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa4971a",
   "metadata": {},
   "source": [
    "Build model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c787dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133be475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_hiddens: int, n_classes: int, feature_extractor: FeatureExtractor):\n",
    "        super().__init__()\n",
    "        self.n_hiddens: int = n_hiddens\n",
    "        self.n_classes: int = n_classes\n",
    "        self.feature_extractor: FeatureExtractor = feature_extractor\n",
    "        self.fc1 = nn.LazyLinear(out_features=n_hiddens)\n",
    "        self.fc2 = nn.LazyLinear(out_features=n_hiddens)\n",
    "        self.fc3 = nn.LazyLinear(out_features=n_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x: np.ndarray = x.numpy()\n",
    "        \n",
    "        features: List[np.ndarray] = []\n",
    "        for image in x:\n",
    "            feature = self.feature_extractor(image_array=image)\n",
    "            features.append(feature)\n",
    "        \n",
    "        features = torch.tensor(data=np.array(features), dtype=torch.float)\n",
    "        y = torch.relu(self.fc1(features))\n",
    "        y = torch.relu(self.fc2(y))\n",
    "        y = torch.softmax(self.fc3(y), dim=1)\n",
    "        return y\n",
    "\n",
    "    def predict(self, test_dataloader: DataLoader) -> None:\n",
    "        self.eval()\n",
    "\n",
    "        filenames = []\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images, fnames in test_dataloader:\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                filenames.extend(fnames)\n",
    "                predictions.extend(list(predicted.numpy()))\n",
    "\n",
    "        prediction_table = pd.DataFrame(\n",
    "            data={'image': filenames, 'label': predictions}\n",
    "        )\n",
    "        prediction_table.to_csv('neural_net.csv', header=False, index=False)\n",
    "        return prediction_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c45b84",
   "metadata": {},
   "source": [
    "# 2. Train your model using dog heart datasets (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9da66",
   "metadata": {},
   "source": [
    "Load datasets and dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70c18bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Train')\n",
    "valid_dataset = DogHeartLabeledDataset(data_root='Dog_heart/Valid')\n",
    "test_dataset = DogHearUnlabeledDataset(data_root='Test')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f13124",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9798f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dlenv/lib/python3.6/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0503\n",
      "Epoch [2/5], Loss: 0.9989\n",
      "Epoch [3/5], Loss: 0.9158\n",
      "Epoch [4/5], Loss: 0.8659\n",
      "Epoch [5/5], Loss: 0.7836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1709.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1919.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1804.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1685.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1833.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1900.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1824.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1907.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0    1922.png      1\n",
       "1    1709.png      1\n",
       "2    1919.png      0\n",
       "3    1639.png      0\n",
       "4    1804.png      2\n",
       "..        ...    ...\n",
       "395  1685.png      2\n",
       "396  1833.png      2\n",
       "397  1900.png      0\n",
       "398  1824.png      2\n",
       "399  1907.png      2\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet(n_hiddens=64, n_classes=3, feature_extractor=HOG())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, filenames in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader):.4f}')\n",
    "    \n",
    "test_dataset = DogHearUnlabeledDataset(data_root='Test')\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "net.predict(test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63262f",
   "metadata": {},
   "source": [
    "# 3. Evaluate your model using the developed software (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1b005",
   "metadata": {},
   "source": [
    "`Neural Network + HOG`:\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/hiepdang-ml/DLAssignment3/master/NeuralNet.png\" style=\"width:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b4fc6",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
